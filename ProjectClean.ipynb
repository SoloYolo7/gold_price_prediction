{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arutt\\Desktop\\ProjectRegress\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from pmdarima import auto_arima\n",
    "    from statsmodels.tsa.arima.model import ARIMA\n",
    "    from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "    ARIMA_AVAILABLE = True\n",
    "except ImportError:\n",
    "    ARIMA_AVAILABLE = False\n",
    "    print(\"Библиотеки для ARIMA/SARIMA (pmdarima, statsmodels) не найдены. Модели будут пропущены.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow URI установлен.\n"
     ]
    }
   ],
   "source": [
    "MLFLOW_EXPERIMENT_NAME = \"Financial_Gold_Prediction_With_ARIMA\"\n",
    "mlflow.set_tracking_uri(\"http://84.201.144.227:8000\") \n",
    "print(\"MLflow URI установлен.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/financial_regression.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.set_index('date')\n",
    "df.dropna(subset=['gold close'], inplace=True)\n",
    "\n",
    "# Создание временных признаков\n",
    "df['year'] = df.index.year\n",
    "df['month'] = df.index.month\n",
    "df['dayofweek'] = df.index.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = df.copy()\n",
    "key_features = ['silver close', 'oil close', 'dxy close']\n",
    "key_features = [col for col in key_features if col in df_fe.columns]\n",
    "\n",
    "for col in key_features:\n",
    "    df_fe[f'{col}_lag1'] = df_fe[col].shift(1)\n",
    "    df_fe[f'{col}_roll_mean3'] = df_fe[col].rolling(window=3).mean()\n",
    "\n",
    "df_fe[f'gold_close_lag1'] = df_fe['gold close'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_with_lags = df_fe['gold close']\n",
    "X_with_lags = df_fe.drop(columns=['gold close'])\n",
    "\n",
    "mask_y_notna = y_with_lags.notna()\n",
    "y_clean_for_split = y_with_lags[mask_y_notna]\n",
    "X_clean_for_split = X_with_lags[mask_y_notna]\n",
    "\n",
    "# Импутация\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "split_index = int(len(X_clean_for_split) * 0.8)\n",
    "X_train_raw, X_test_raw = X_clean_for_split.iloc[:split_index], X_clean_for_split.iloc[split_index:]\n",
    "y_train_raw, y_test_raw = y_clean_for_split.iloc[:split_index], y_clean_for_split.iloc[split_index:]\n",
    "\n",
    "X_train_imputed = pd.DataFrame(\n",
    "    imputer.fit_transform(X_train_raw),\n",
    "    columns=X_train_raw.columns,\n",
    "    index=X_train_raw.index\n",
    ")\n",
    "X_test_imputed = pd.DataFrame(\n",
    "    imputer.transform(X_test_raw),\n",
    "    columns=X_test_raw.columns,\n",
    "    index=X_test_raw.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_true, y_pred):\n",
    "    mask = pd.notna(y_true) & pd.notna(y_pred)\n",
    "    y_true_clean = y_true[mask]\n",
    "    y_pred_clean = y_pred[mask]\n",
    "    if len(y_true_clean) == 0:\n",
    "        return {'mae': np.nan, 'mse': np.nan, 'rmse': np.nan, 'r2': np.nan, 'mape': np.nan}\n",
    "\n",
    "    return {\n",
    "        'mae': mean_absolute_error(y_true_clean, y_pred_clean),\n",
    "        'mse': mean_squared_error(y_true_clean, y_pred_clean),\n",
    "        'rmse': np.sqrt(mean_squared_error(y_true_clean, y_pred_clean)),\n",
    "        'r2': r2_score(y_true_clean, y_pred_clean),\n",
    "        'mape': mean_absolute_percentage_error(y_true_clean, y_pred_clean)\n",
    "    }\n",
    "\n",
    "def report_metrics(mlflow_obj, y_true, y_pred, model_name):\n",
    "    \"\"\"Адаптированная функция для логирования метрик регрессии в MLflow.\"\"\"\n",
    "    metrics = calc_metrics(y_true, y_pred)\n",
    "    print(f\"\\n--- Метрики для {model_name} ---\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k.upper()}: {v:.4f}\")\n",
    "        if mlflow_obj: # Проверка, доступен ли MLflow\n",
    "             mlflow_obj.log_metric(f\"{k}_{model_name}\", v)\n",
    "    return metrics\n",
    "\n",
    "def run_experiment(model, model_name, params, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Запуск эксперимента с логированием в MLflow.\"\"\"\n",
    "    print(f\"\\n--- Запуск эксперимента: {model_name} ---\")\n",
    "    \n",
    "    try:\n",
    "        mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)\n",
    "        with mlflow.start_run(run_name=model_name):\n",
    "            # Логирование параметров\n",
    "            if params:\n",
    "                mlflow.log_params(params)\n",
    "            \n",
    "            # Обучение модели\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Предсказание\n",
    "            preds = model.predict(X_test)\n",
    "            \n",
    "            # Вычисление и логирование метрик\n",
    "            metrics = report_metrics(mlflow, y_test, preds, model_name)\n",
    "            \n",
    "            # Логирование модели (если это scikit-learn модель)\n",
    "            if hasattr(model, 'predict'): # Простая проверка\n",
    "                mlflow.sklearn.log_model(model, \"model\") \n",
    "            \n",
    "            print(f\"- {model_name}: Эксперимент завершен. -\")\n",
    "            return model, metrics\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при запуске эксперимента {model_name}: {e}\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_full_series = df['gold close']\n",
    "y_train_series = y_full_series.loc[X_train_imputed.index]\n",
    "y_test_series = y_full_series.loc[X_test_imputed.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train_imputed.columns, index=X_train_imputed.index)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test_imputed.columns, index=X_test_imputed.index)\n",
    "\n",
    "results = {} # Для хранения результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Запуск эксперимента: LinearRegression ---\n",
      "Ошибка при запуске эксперимента LinearRegression: Cannot set a deleted experiment 'Financial_Gold_Prediction_With_ARIMA' as the active experiment. You can restore the experiment, or permanently delete the experiment to create a new one.\n"
     ]
    }
   ],
   "source": [
    "lr_model = LinearRegression()\n",
    "lr_params = {\"model\": \"LinearRegression\"}\n",
    "model_lr, metrics_lr = run_experiment(lr_model, \"LinearRegression\", lr_params, X_train_scaled_df, X_test_scaled_df, y_train_raw, y_test_raw)\n",
    "if model_lr is not None:\n",
    "    results[\"LinearRegression\"] = metrics_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-31 11:58:53,758] A new study created in memory with name: no-name-04b96c27-375b-409e-89ef-afe980371220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LightGBM: Подбор параметров с Optuna...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-31 11:58:55,951] Trial 0 finished with value: 1.5111584604978583 and parameters: {'n_estimators': 274, 'learning_rate': 0.040466462020454015, 'num_leaves': 23, 'max_depth': 6, 'subsample': 0.9942585153864425}. Best is trial 0 with value: 1.5111584604978583.\n",
      "[I 2025-08-31 11:58:56,305] Trial 1 finished with value: 1.526522090060098 and parameters: {'n_estimators': 257, 'learning_rate': 0.0690512301528945, 'num_leaves': 45, 'max_depth': 4, 'subsample': 0.7587872380081007}. Best is trial 0 with value: 1.5111584604978583.\n",
      "[I 2025-08-31 11:58:56,719] Trial 2 finished with value: 1.4602117709232356 and parameters: {'n_estimators': 230, 'learning_rate': 0.05120683943019833, 'num_leaves': 48, 'max_depth': 5, 'subsample': 0.8372404812707501}. Best is trial 2 with value: 1.4602117709232356.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры LightGBM: {'n_estimators': 230, 'learning_rate': 0.05120683943019833, 'num_leaves': 48, 'max_depth': 5, 'subsample': 0.8372404812707501}\n",
      "\n",
      "--- Запуск эксперимента: LightGBM_Optuna ---\n",
      "Ошибка при запуске эксперимента LightGBM_Optuna: Cannot set a deleted experiment 'Financial_Gold_Prediction_With_ARIMA' as the active experiment. You can restore the experiment, or permanently delete the experiment to create a new one.\n"
     ]
    }
   ],
   "source": [
    "def objective_lgbm(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 300),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 50),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 6),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"verbose\": -1\n",
    "    }\n",
    "    rmses = []\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    for train_idx, val_idx in tscv.split(X_train_imputed):\n",
    "        model = LGBMRegressor(**params)\n",
    "        model.fit(X_train_imputed.iloc[train_idx], y_train_raw.iloc[train_idx])\n",
    "        preds = model.predict(X_train_imputed.iloc[val_idx])\n",
    "        metrics = calc_metrics(y_train_raw.iloc[val_idx], preds)\n",
    "        rmses.append(metrics['rmse'] if not np.isnan(metrics['rmse']) else np.inf)\n",
    "    return np.mean(rmses) if rmses else np.inf\n",
    "\n",
    "print(\"\\nLightGBM: Подбор параметров с Optuna...\")\n",
    "study_lgbm = optuna.create_study(direction=\"minimize\")\n",
    "study_lgbm.optimize(objective_lgbm, n_trials=3, timeout=300) \n",
    "print(\"Лучшие параметры LightGBM:\", study_lgbm.best_params)\n",
    "\n",
    "best_params_lgbm = {**study_lgbm.best_params, 'verbose': -1}\n",
    "final_model_lgbm = LGBMRegressor(**best_params_lgbm)\n",
    "model_lgbm, metrics_lgbm = run_experiment(final_model_lgbm, \"LightGBM_Optuna\", best_params_lgbm, X_train_imputed, X_test_imputed, y_train_raw, y_test_raw)\n",
    "if model_lgbm is not None:\n",
    "    results[\"LightGBM\"] = metrics_lgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-31 11:58:56,763] A new study created in memory with name: no-name-11afd2dd-f9e1-4152-aae2-afebb2493f55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CatBoost: Подбор параметров с Optuna...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-31 11:58:58,182] Trial 0 finished with value: 5.580786524688123 and parameters: {'iterations': 292, 'learning_rate': 0.06692921931385888, 'depth': 3, 'l2_leaf_reg': 1.0572825647650832}. Best is trial 0 with value: 5.580786524688123.\n",
      "[I 2025-08-31 11:59:01,465] Trial 1 finished with value: 13.895908802792235 and parameters: {'iterations': 266, 'learning_rate': 0.012859902538182161, 'depth': 6, 'l2_leaf_reg': 1.9764200268490992}. Best is trial 0 with value: 5.580786524688123.\n",
      "[I 2025-08-31 11:59:04,985] Trial 2 finished with value: 12.262269610327635 and parameters: {'iterations': 280, 'learning_rate': 0.06479247378011803, 'depth': 6, 'l2_leaf_reg': 2.0977369268718897}. Best is trial 0 with value: 5.580786524688123.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры CatBoost: {'iterations': 292, 'learning_rate': 0.06692921931385888, 'depth': 3, 'l2_leaf_reg': 1.0572825647650832}\n",
      "\n",
      "--- Запуск эксперимента: CatBoost_Optuna ---\n",
      "Ошибка при запуске эксперимента CatBoost_Optuna: Cannot set a deleted experiment 'Financial_Gold_Prediction_With_ARIMA' as the active experiment. You can restore the experiment, or permanently delete the experiment to create a new one.\n"
     ]
    }
   ],
   "source": [
    "def objective_catboost(trial):\n",
    "    params = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 100, 300),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 3, 6),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1, 5, log=True),\n",
    "        \"verbose\": 0\n",
    "    }\n",
    "    rmses = []\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    for train_idx, val_idx in tscv.split(X_train_imputed):\n",
    "        model = CatBoostRegressor(**params)\n",
    "        model.fit(X_train_imputed.iloc[train_idx], y_train_raw.iloc[train_idx], early_stopping_rounds=10, verbose=0)\n",
    "        preds = model.predict(X_train_imputed.iloc[val_idx])\n",
    "        metrics = calc_metrics(y_train_raw.iloc[val_idx], preds)\n",
    "        rmses.append(metrics['rmse'] if not np.isnan(metrics['rmse']) else np.inf)\n",
    "    return np.mean(rmses) if rmses else np.inf\n",
    "\n",
    "print(\"\\nCatBoost: Подбор параметров с Optuna...\")\n",
    "study_catboost = optuna.create_study(direction=\"minimize\")\n",
    "study_catboost.optimize(objective_catboost, n_trials=3, timeout=300)\n",
    "print(\"Лучшие параметры CatBoost:\", study_catboost.best_params)\n",
    "\n",
    "best_params_catboost = {**study_catboost.best_params, 'verbose': 0}\n",
    "final_model_catboost = CatBoostRegressor(**best_params_catboost)\n",
    "model_catboost, metrics_catboost = run_experiment(final_model_catboost, \"CatBoost_Optuna\", best_params_catboost, X_train_imputed, X_test_imputed, y_train_raw, y_test_raw)\n",
    "if model_catboost is not None:\n",
    "    results[\"CatBoost\"] = metrics_catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-31 11:59:05,027] A new study created in memory with name: no-name-ce6c4c35-8449-4b59-beef-9c4995d3a25a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost: Подбор параметров с Optuna...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-31 11:59:06,219] Trial 0 finished with value: 5.282350953162805 and parameters: {'n_estimators': 153, 'learning_rate': 0.011435449395281815, 'max_depth': 6, 'subsample': 0.7943108257636885, 'colsample_bytree': 0.9404098003082748}. Best is trial 0 with value: 5.282350953162805.\n",
      "[I 2025-08-31 11:59:07,200] Trial 1 finished with value: 1.8420445479454288 and parameters: {'n_estimators': 176, 'learning_rate': 0.04534625006623747, 'max_depth': 5, 'subsample': 0.7267727366557938, 'colsample_bytree': 0.7033346165251708}. Best is trial 1 with value: 1.8420445479454288.\n",
      "[I 2025-08-31 11:59:08,779] Trial 2 finished with value: 2.204995355715873 and parameters: {'n_estimators': 196, 'learning_rate': 0.031974950721968785, 'max_depth': 6, 'subsample': 0.6782038886975436, 'colsample_bytree': 0.6162734478962333}. Best is trial 1 with value: 1.8420445479454288.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры XGBoost: {'n_estimators': 176, 'learning_rate': 0.04534625006623747, 'max_depth': 5, 'subsample': 0.7267727366557938, 'colsample_bytree': 0.7033346165251708}\n",
      "\n",
      "--- Запуск эксперимента: XGBoost_Optuna ---\n",
      "Ошибка при запуске эксперимента XGBoost_Optuna: Cannot set a deleted experiment 'Financial_Gold_Prediction_With_ARIMA' as the active experiment. You can restore the experiment, or permanently delete the experiment to create a new one.\n"
     ]
    }
   ],
   "source": [
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 6),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "    }\n",
    "    rmses = []\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    for train_idx, val_idx in tscv.split(X_train_imputed):\n",
    "        model = XGBRegressor(**params)\n",
    "        model.fit(X_train_imputed.iloc[train_idx], y_train_raw.iloc[train_idx], verbose=0)\n",
    "        preds = model.predict(X_train_imputed.iloc[val_idx])\n",
    "        metrics = calc_metrics(y_train_raw.iloc[val_idx], preds)\n",
    "        rmses.append(metrics['rmse'] if not np.isnan(metrics['rmse']) else np.inf)\n",
    "    return np.mean(rmses) if rmses else np.inf\n",
    "\n",
    "print(\"\\nXGBoost: Подбор параметров с Optuna...\")\n",
    "study_xgb = optuna.create_study(direction=\"minimize\")\n",
    "study_xgb.optimize(objective_xgb, n_trials=3, timeout=300)\n",
    "print(\"Лучшие параметры XGBoost:\", study_xgb.best_params)\n",
    "\n",
    "best_params_xgb = study_xgb.best_params\n",
    "final_model_xgb = XGBRegressor(**best_params_xgb)\n",
    "model_xgb, metrics_xgb = run_experiment(final_model_xgb, \"XGBoost_Optuna\", best_params_xgb, X_train_imputed, X_test_imputed, y_train_raw, y_test_raw)\n",
    "if model_xgb is not None:\n",
    "    results[\"XGBoost\"] = metrics_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"\\n--- Подготовка данных для ARIMA/SARIMA ---\")\n",
    "# print(f\"Размер обучающего ряда: {y_train_series.shape}\")\n",
    "# print(f\"Размер тестового ряда: {y_test_series.shape}\")\n",
    "\n",
    "# if ARIMA_AVAILABLE:\n",
    "#     # --- Модель 5: ARIMA ---\n",
    "#     print(\"\\n--- Обучение ARIMA ---\")\n",
    "#     try:\n",
    "#         # Используем фиксированные параметры для демонстрации\n",
    "#         order = (1, 1, 1) # (p, d, q) - пример, подберите под свои данные\n",
    "#         print(f\"Используем фиксированные параметры ARIMA: {order}\")\n",
    "        \n",
    "#         # Прогноз на тестовую выборку (walk-forward)\n",
    "#         forecast_arima = []\n",
    "#         history = list(y_train_series) # История начинается с обучающих данных\n",
    "#         for t in range(len(y_test_series)):\n",
    "#             model_temp = ARIMA(history, order=order).fit()\n",
    "#             yhat = model_temp.forecast(steps=1)[0]\n",
    "#             forecast_arima.append(yhat)\n",
    "#             # Добавляем фактическое значение из теста в историю (walk-forward)\n",
    "#             history.append(y_test_series.iloc[t]) \n",
    "        \n",
    "#         forecast_arima = pd.Series(forecast_arima, index=y_test_series.index)\n",
    "        \n",
    "#         # Оценка ARIMA и логирование в MLflow\n",
    "#         print(f\"\\n--- Запуск эксперимента: ARIMA ---\")\n",
    "#         try:\n",
    "#             mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)\n",
    "#             with mlflow.start_run(run_name=\"ARIMA\"):\n",
    "#                 mlflow.log_params({'order': str(order)}) # Преобразуем tuple в строку для логирования\n",
    "#                 metrics_arima = report_metrics(mlflow, y_test_series, forecast_arima, \"ARIMA\")\n",
    "#                 # Модель ARIMA не сохраняется как sklearn, поэтому пропускаем log_model\n",
    "#                 print(f\"- ARIMA: Эксперимент завершен. -\")\n",
    "#                 results[\"ARIMA\"] = metrics_arima\n",
    "#         except Exception as e:\n",
    "#             print(f\"Ошибка при логировании ARIMA в MLflow: {e}\")\n",
    "#             # В случае ошибки MLflow, все равно сохраняем результаты\n",
    "#             metrics_arima = calc_metrics(y_test_series, forecast_arima)\n",
    "#             print(f\"\\n--- Метрики для ARIMA ---\")\n",
    "#             for k, v in metrics_arima.items():\n",
    "#                 print(f\"  {k.upper()}: {v:.4f}\")\n",
    "#             results[\"ARIMA\"] = metrics_arima\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         print(f\"Ошибка при обучении/оценке ARIMA: {e}\")\n",
    "#         results[\"ARIMA\"] = {\"mae\": np.nan, \"mse\": np.nan, \"rmse\": np.nan, \"r2\": np.nan, \"mape\": np.nan}\n",
    "\n",
    "\n",
    "#     # --- Модель 6: SARIMA ---\n",
    "#     print(\"\\n--- Обучение SARIMA ---\")\n",
    "#     try:\n",
    "#         # Используем фиксированные параметры для демонстрации\n",
    "#         order_s = (1, 1, 1) # (p, d, q)\n",
    "#         seasonal_order = (1, 1, 1, 12) # (P, D, Q, s) - s=12 для годовой сезонности\n",
    "#         print(f\"Используем фиксированные параметры SARIMA: {order_s} x {seasonal_order}\")\n",
    "        \n",
    "#         # Прогноз на тестовую выборку (walk-forward)\n",
    "#         forecast_sarima = []\n",
    "#         history_s = list(y_train_series)\n",
    "#         for t in range(len(y_test_series)):\n",
    "#             model_temp_s = SARIMAX(history_s, order=order_s, seasonal_order=seasonal_order).fit(disp=False)\n",
    "#             yhat_s = model_temp_s.forecast(steps=1)[0]\n",
    "#             forecast_sarima.append(yhat_s)\n",
    "#             history_s.append(y_test_series.iloc[t]) \n",
    "        \n",
    "#         forecast_sarima = pd.Series(forecast_sarima, index=y_test_series.index)\n",
    "        \n",
    "#         # Оценка SARIMA и логирование в MLflow\n",
    "#         print(f\"\\n--- Запуск эксперимента: SARIMA ---\")\n",
    "#         try:\n",
    "#             mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)\n",
    "#             with mlflow.start_run(run_name=\"SARIMA\"):\n",
    "#                 mlflow.log_params({\n",
    "#                     'order': str(order_s),\n",
    "#                     'seasonal_order': str(seasonal_order)\n",
    "#                 })\n",
    "#                 metrics_sarima = report_metrics(mlflow, y_test_series, forecast_sarima, \"SARIMA\")\n",
    "#                 # Модель SARIMA не сохраняется как sklearn, поэтому пропускаем log_model\n",
    "#                 print(f\"- SARIMA: Эксперимент завершен. -\")\n",
    "#                 results[\"SARIMA\"] = metrics_sarima\n",
    "#         except Exception as e:\n",
    "#             print(f\"Ошибка при логировании SARIMA в MLflow: {e}\")\n",
    "#             # В случае ошибки MLflow, все равно сохраняем результаты\n",
    "#             metrics_sarima = calc_metrics(y_test_series, forecast_sarima)\n",
    "#             print(f\"\\n--- Метрики для SARIMA ---\")\n",
    "#             for k, v in metrics_sarima.items():\n",
    "#                 print(f\"  {k.upper()}: {v:.4f}\")\n",
    "#             results[\"SARIMA\"] = metrics_sarima\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         print(f\"Ошибка при обучении/оценке SARIMA: {e}\")\n",
    "#         results[\"SARIMA\"] = {\"mae\": np.nan, \"mse\": np.nan, \"rmse\": np.nan, \"r2\": np.nan, \"mape\": np.nan}\n",
    "\n",
    "# else:\n",
    "#     print(\"\\nARIMA/SARIMA модели пропущены из-за отсутствия необходимых библиотек.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================\n",
      "          СВОДКА РЕЗУЛЬТАТОВ             \n",
      "=========================================\n",
      "Нет результатов для отображения.\n",
      "\n",
      "--- Все эксперименты завершены ---\n",
      "Проверьте MLflow UI по адресу http://84.201.144.227:8000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=========================================\")\n",
    "print(\"          СВОДКА РЕЗУЛЬТАТОВ             \")\n",
    "print(\"=========================================\")\n",
    "if results:\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    print(results_df.round(4))\n",
    "    if not results_df.empty:\n",
    "        best_model_name = results_df['rmse'].idxmin()\n",
    "        best_rmse = results_df.loc[best_model_name, 'rmse']\n",
    "        print(f\"\\nЛучшая модель по RMSE: {best_model_name} (RMSE = {best_rmse:.4f})\")\n",
    "else:\n",
    "    print(\"Нет результатов для отображения.\")\n",
    "\n",
    "print(\"\\n--- Все эксперименты завершены ---\")\n",
    "print(\"Проверьте MLflow UI по адресу http://84.201.144.227:8000\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
