{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline ### –ò–ó–ú–ï–ù–ï–ù–ò–ï 1: –î–æ–±–∞–≤–ª–µ–Ω –∏–º–ø–æ—Ä—Ç Pipeline\n",
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.pyfunc ### –ò–ó–ú–ï–ù–ï–ù–ò–ï 2: –î–æ–±–∞–≤–ª–µ–Ω –∏–º–ø–æ—Ä—Ç pyfunc\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow URI —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.\n"
     ]
    }
   ],
   "source": [
    "MLFLOW_EXPERIMENT_NAME = \"Financial_Gold_Prediction_v2\" # –ù–æ–≤–æ–µ –∏–º—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
    "mlflow.set_tracking_uri(\"http://84.201.144.227:8000\") \n",
    "print(\"MLflow URI —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/financial_regression.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.set_index('date')\n",
    "df.dropna(subset=['gold close'], inplace=True)\n",
    "df['year'] = df.index.year\n",
    "df['month'] = df.index.month\n",
    "df['dayofweek'] = df.index.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = df.copy()\n",
    "key_features = ['silver close', 'oil close', 'dxy close']\n",
    "key_features = [col for col in key_features if col in df_fe.columns]\n",
    "for col in key_features:\n",
    "    df_fe[f'{col}_lag1'] = df_fe[col].shift(1)\n",
    "    df_fe[f'{col}_roll_mean3'] = df_fe[col].rolling(window=3).mean()\n",
    "df_fe[f'gold_close_lag1'] = df_fe['gold close'].shift(1)\n",
    "y_with_lags = df_fe['gold close']\n",
    "X_with_lags = df_fe.drop(columns=['gold close'])\n",
    "mask_y_notna = y_with_lags.notna()\n",
    "y_clean_for_split = y_with_lags[mask_y_notna]\n",
    "X_clean_for_split = X_with_lags[mask_y_notna]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_global = SimpleImputer(strategy='mean') # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–¥–∏–Ω –∏–º–ø—å—é—Ç–µ—Ä\n",
    "split_index = int(len(X_clean_for_split) * 0.8)\n",
    "X_train_raw, X_test_raw = X_clean_for_split.iloc[:split_index], X_clean_for_split.iloc[split_index:]\n",
    "y_train_raw, y_test_raw = y_clean_for_split.iloc[:split_index], y_clean_for_split.iloc[split_index:]\n",
    "X_train_imputed = pd.DataFrame(imputer_global.fit_transform(X_train_raw), columns=X_train_raw.columns, index=X_train_raw.index)\n",
    "X_test_imputed = pd.DataFrame(imputer_global.transform(X_test_raw), columns=X_test_raw.columns, index=X_test_raw.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_true, y_pred):\n",
    "    mask = pd.notna(y_true) & pd.notna(y_pred)\n",
    "    y_true_clean, y_pred_clean = y_true[mask], y_pred[mask]\n",
    "    if len(y_true_clean) == 0: return {'mae': np.nan, 'mse': np.nan, 'rmse': np.nan, 'r2': np.nan, 'mape': np.nan}\n",
    "    return {'mae': mean_absolute_error(y_true_clean, y_pred_clean), 'mse': mean_squared_error(y_true_clean, y_pred_clean),\n",
    "            'rmse': np.sqrt(mean_squared_error(y_true_clean, y_pred_clean)), 'r2': r2_score(y_true_clean, y_pred_clean),\n",
    "            'mape': mean_absolute_percentage_error(y_true_clean, y_pred_clean)}\n",
    "def report_metrics(mlflow_obj, y_true, y_pred, model_name):\n",
    "    metrics = calc_metrics(y_true, y_pred)\n",
    "    print(f\"\\n--- –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è {model_name} ---\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k.upper()}: {v:.4f}\")\n",
    "        if mlflow_obj: mlflow_obj.log_metric(f\"{k}_{model_name}\", v)\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arutt\\Desktop\\ProjectRegress\\.venv\\lib\\site-packages\\mlflow\\pyfunc\\utils\\data_validation.py:186: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n"
     ]
    }
   ],
   "source": [
    "class ModelPipelineWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, pipeline):\n",
    "        self.pipeline = pipeline\n",
    "    def predict(self, context, model_input):\n",
    "        return self.pipeline.predict(model_input)\n",
    "\n",
    "def run_experiment(model, model_name, params, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"–ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ —Å –ì–ê–†–ê–ù–¢–ò–†–û–í–ê–ù–ù–´–ú –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ pyfunc.\"\"\"\n",
    "    print(f\"\\n--- –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞: {model_name} ---\")\n",
    "    \n",
    "    # –ú—ã –±—É–¥–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å –ø–∞–π–ø–ª–∞–π–Ω (imputer + model)\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')), # –°–æ–∑–¥–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω –∑–¥–µ—Å—å\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)\n",
    "        with mlflow.start_run(run_name=model_name) as run:\n",
    "            if params:\n",
    "                mlflow.log_params(params)\n",
    "            \n",
    "            # –û–±—É—á–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            \n",
    "            preds = pipeline.predict(X_test)\n",
    "            metrics = report_metrics(mlflow, y_test, preds, model_name)\n",
    "            \n",
    "            # --- –ì–ê–†–ê–ù–¢–ò–†–û–í–ê–ù–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ò ---\n",
    "            print(\"–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ mlflow.pyfunc...\")\n",
    "            wrapped_model = ModelPipelineWrapper(pipeline)\n",
    "            \n",
    "            # –°–æ–±–∏—Ä–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏\n",
    "            pip_requirements = [\n",
    "                'mlflow', 'scikit-learn', 'pandas', 'numpy',\n",
    "                'xgboost', 'lightgbm', 'catboost', 'cloudpickle'\n",
    "            ]\n",
    "            \n",
    "            mlflow.pyfunc.log_model(\n",
    "                artifact_path=\"model_pipeline\", # <- –í–∞–∂–Ω–æ–µ –∏–º—è –ø–∞–ø–∫–∏\n",
    "                python_model=wrapped_model,\n",
    "                pip_requirements=pip_requirements,\n",
    "                input_example=X_train.head(5) # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä –¥–ª—è —Å—Ö–µ–º—ã\n",
    "            )\n",
    "            print(f\"‚úÖ –ú–æ–¥–µ–ª—å '{model_name}' —É—Å–ø–µ—à–Ω–æ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞.\")\n",
    "            \n",
    "            # –°–æ—Ö—Ä–∞–Ω—è–µ–º RUN_ID –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ API\n",
    "            run_id = run.info.run_id\n",
    "            with open(f\"{model_name}_run_id.txt\", \"w\") as f:\n",
    "                f.write(run_id)\n",
    "            mlflow.log_artifact(f\"{model_name}_run_id.txt\")\n",
    "            print(f\"RUN_ID –¥–ª—è —ç—Ç–æ–π –º–æ–¥–µ–ª–∏: {run_id}\")\n",
    "\n",
    "            return pipeline, metrics\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ {model_name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_full_series = df['gold close']\n",
    "y_train_series = y_full_series.loc[X_train_imputed.index]\n",
    "y_test_series = y_full_series.loc[X_test_imputed.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {} # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 23:58:24,490] A new study created in memory with name: no-name-caccfb5f-ae17-42c5-97ae-43ea3337056c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LightGBM: –ü–æ–¥–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å Optuna...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 23:58:26,406] Trial 0 finished with value: 18.594644030876733 and parameters: {'n_estimators': 282, 'learning_rate': 0.029169811614400677, 'num_leaves': 33, 'max_depth': 6, 'subsample': 0.9412549345775878}. Best is trial 0 with value: 18.594644030876733.\n",
      "[I 2025-09-01 23:58:26,501] Trial 1 finished with value: 18.64718688619543 and parameters: {'n_estimators': 155, 'learning_rate': 0.03250242018391508, 'num_leaves': 44, 'max_depth': 3, 'subsample': 0.867472560212041}. Best is trial 0 with value: 18.594644030876733.\n",
      "[I 2025-09-01 23:58:26,635] Trial 2 finished with value: 18.51851138688786 and parameters: {'n_estimators': 254, 'learning_rate': 0.026215681949906058, 'num_leaves': 35, 'max_depth': 3, 'subsample': 0.8144085423729818}. Best is trial 2 with value: 18.51851138688786.\n",
      "2025/09/01 23:58:26 INFO mlflow.tracking.fluent: Experiment with name 'Financial_Gold_Prediction_v2' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞: LightGBM_Optuna ---\n",
      "\n",
      "--- –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è LightGBM_Optuna ---\n",
      "  MAE: 8.8641\n",
      "  MSE: 342.9353\n",
      "  RMSE: 18.5185\n",
      "  R2: 0.3207\n",
      "  MAPE: 0.0399\n",
      "–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ mlflow.pyfunc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/01 23:58:27 INFO mlflow.pyfunc: Inferring model signature from input example\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2177dd1a65e04b398f6c62827fbec09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –ú–æ–¥–µ–ª—å 'LightGBM_Optuna' —É—Å–ø–µ—à–Ω–æ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞.\n",
      "RUN_ID –¥–ª—è —ç—Ç–æ–π –º–æ–¥–µ–ª–∏: e71ac7626f8548edab1a342a26e15766\n",
      "üèÉ View run LightGBM_Optuna at: http://84.201.144.227:8000/#/experiments/10/runs/e71ac7626f8548edab1a342a26e15766\n",
      "üß™ View experiment at: http://84.201.144.227:8000/#/experiments/10\n"
     ]
    }
   ],
   "source": [
    "def objective_lgbm(trial):\n",
    "    params = {\"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 300), \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "              \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 50), \"max_depth\": trial.suggest_int(\"max_depth\", 3, 6),\n",
    "              \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0), \"verbose\": -1}\n",
    "    model = LGBMRegressor(**params)\n",
    "    pipe = Pipeline([('imputer', SimpleImputer(strategy='mean')), ('model', model)])\n",
    "    pipe.fit(X_train_raw, y_train_raw)\n",
    "    preds = pipe.predict(X_test_raw)\n",
    "    metrics = calc_metrics(y_test_raw, preds)\n",
    "    return metrics['rmse'] if not np.isnan(metrics['rmse']) else np.inf\n",
    "\n",
    "print(\"\\nLightGBM: –ü–æ–¥–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å Optuna...\")\n",
    "study_lgbm = optuna.create_study(direction=\"minimize\")\n",
    "study_lgbm.optimize(objective_lgbm, n_trials=3, timeout=300) \n",
    "best_params_lgbm = {**study_lgbm.best_params, 'verbose': -1}\n",
    "final_model_lgbm = LGBMRegressor(**best_params_lgbm)\n",
    "model_lgbm, metrics_lgbm = run_experiment(final_model_lgbm, \"LightGBM_Optuna\", best_params_lgbm, X_train_raw, y_train_raw, X_test_raw, y_test_raw)\n",
    "if model_lgbm is not None:\n",
    "    results[\"LightGBM\"] = metrics_lgbm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 23:58:31,917] A new study created in memory with name: no-name-d6ad6c1c-1927-41ab-9be3-575f41c33f38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CatBoost: –ü–æ–¥–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å Optuna...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 23:58:32,866] Trial 0 finished with value: 21.809602048170145 and parameters: {'iterations': 252, 'learning_rate': 0.020214553356790094, 'depth': 5, 'l2_leaf_reg': 3.423987473922204}. Best is trial 0 with value: 21.809602048170145.\n",
      "[I 2025-09-01 23:58:34,276] Trial 1 finished with value: 19.905133854386545 and parameters: {'iterations': 232, 'learning_rate': 0.09029065797789809, 'depth': 6, 'l2_leaf_reg': 1.9058785297010918}. Best is trial 1 with value: 19.905133854386545.\n",
      "[I 2025-09-01 23:58:34,779] Trial 2 finished with value: 20.03023612502932 and parameters: {'iterations': 201, 'learning_rate': 0.056452081921453984, 'depth': 4, 'l2_leaf_reg': 1.099557678619075}. Best is trial 1 with value: 19.905133854386545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞: CatBoost_Optuna ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/01 23:58:36 INFO mlflow.pyfunc: Inferring model signature from input example\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è CatBoost_Optuna ---\n",
      "  MAE: 10.8037\n",
      "  MSE: 396.2144\n",
      "  RMSE: 19.9051\n",
      "  R2: 0.2152\n",
      "  MAPE: 0.0501\n",
      "–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ mlflow.pyfunc...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83600713ba46454d99354a49f73dde55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –ú–æ–¥–µ–ª—å 'CatBoost_Optuna' —É—Å–ø–µ—à–Ω–æ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞.\n",
      "RUN_ID –¥–ª—è —ç—Ç–æ–π –º–æ–¥–µ–ª–∏: f1262bc2f6414c729dbd57a885dc033f\n",
      "üèÉ View run CatBoost_Optuna at: http://84.201.144.227:8000/#/experiments/10/runs/f1262bc2f6414c729dbd57a885dc033f\n",
      "üß™ View experiment at: http://84.201.144.227:8000/#/experiments/10\n"
     ]
    }
   ],
   "source": [
    "def objective_catboost(trial):\n",
    "    params = {\"iterations\": trial.suggest_int(\"iterations\", 100, 300), \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "              \"depth\": trial.suggest_int(\"depth\", 3, 6), \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1, 5, log=True), \"verbose\": 0}\n",
    "    model = CatBoostRegressor(**params)\n",
    "    pipe = Pipeline([('imputer', SimpleImputer(strategy='mean')), ('model', model)])\n",
    "    pipe.fit(X_train_raw, y_train_raw)\n",
    "    preds = pipe.predict(X_test_raw)\n",
    "    metrics = calc_metrics(y_test_raw, preds)\n",
    "    return metrics['rmse'] if not np.isnan(metrics['rmse']) else np.inf\n",
    "\n",
    "print(\"\\nCatBoost: –ü–æ–¥–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å Optuna...\")\n",
    "study_catboost = optuna.create_study(direction=\"minimize\")\n",
    "study_catboost.optimize(objective_catboost, n_trials=3, timeout=300)\n",
    "best_params_catboost = {**study_catboost.best_params, 'verbose': 0}\n",
    "final_model_catboost = CatBoostRegressor(**best_params_catboost)\n",
    "model_catboost, metrics_catboost = run_experiment(final_model_catboost, \"CatBoost_Optuna\", best_params_catboost, X_train_raw, y_train_raw, X_test_raw, y_test_raw)\n",
    "if model_catboost is not None:\n",
    "    results[\"CatBoost\"] = metrics_catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 23:58:37,161] A new study created in memory with name: no-name-752189bf-f621-4909-9018-fcbd4786fe55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost: –ü–æ–¥–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å Optuna...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 23:58:37,382] Trial 0 finished with value: 18.18820210617311 and parameters: {'n_estimators': 123, 'learning_rate': 0.043587289889896776, 'max_depth': 4, 'subsample': 0.8392521026834094, 'colsample_bytree': 0.614211066500788}. Best is trial 0 with value: 18.18820210617311.\n",
      "[I 2025-09-01 23:58:37,705] Trial 1 finished with value: 18.011829838104674 and parameters: {'n_estimators': 138, 'learning_rate': 0.05535073387760788, 'max_depth': 5, 'subsample': 0.6614423904239255, 'colsample_bytree': 0.844667413729015}. Best is trial 1 with value: 18.011829838104674.\n",
      "[I 2025-09-01 23:58:38,337] Trial 2 finished with value: 18.436301173614442 and parameters: {'n_estimators': 145, 'learning_rate': 0.0315634562791395, 'max_depth': 6, 'subsample': 0.9621398688619633, 'colsample_bytree': 0.9057907436643964}. Best is trial 1 with value: 18.011829838104674.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞: XGBoost_Optuna ---\n",
      "\n",
      "--- –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è XGBoost_Optuna ---\n",
      "  MAE: 8.5694\n",
      "  MSE: 324.4260\n",
      "  RMSE: 18.0118\n",
      "  R2: 0.3574\n",
      "  MAPE: 0.0386\n",
      "–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ mlflow.pyfunc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/01 23:58:39 INFO mlflow.pyfunc: Inferring model signature from input example\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c5d487459c485297bcec737042ab87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –ú–æ–¥–µ–ª—å 'XGBoost_Optuna' —É—Å–ø–µ—à–Ω–æ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞.\n",
      "RUN_ID –¥–ª—è —ç—Ç–æ–π –º–æ–¥–µ–ª–∏: 82d0a09af0d144f3bdc3f7111ea5b099\n",
      "üèÉ View run XGBoost_Optuna at: http://84.201.144.227:8000/#/experiments/10/runs/82d0a09af0d144f3bdc3f7111ea5b099\n",
      "üß™ View experiment at: http://84.201.144.227:8000/#/experiments/10\n"
     ]
    }
   ],
   "source": [
    "def objective_xgb(trial):\n",
    "    params = {'objective': 'reg:squarederror', 'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "              'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True), 'max_depth': trial.suggest_int('max_depth', 3, 6),\n",
    "              'subsample': trial.suggest_float('subsample', 0.6, 1.0), 'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0)}\n",
    "    model = XGBRegressor(**params)\n",
    "    pipe = Pipeline([('imputer', SimpleImputer(strategy='mean')), ('model', model)])\n",
    "    pipe.fit(X_train_raw, y_train_raw)\n",
    "    preds = pipe.predict(X_test_raw)\n",
    "    metrics = calc_metrics(y_test_raw, preds)\n",
    "    return metrics['rmse'] if not np.isnan(metrics['rmse']) else np.inf\n",
    "\n",
    "print(\"\\nXGBoost: –ü–æ–¥–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å Optuna...\")\n",
    "study_xgb = optuna.create_study(direction=\"minimize\")\n",
    "study_xgb.optimize(objective_xgb, n_trials=3, timeout=300)\n",
    "best_params_xgb = study_xgb.best_params\n",
    "final_model_xgb = XGBRegressor(**best_params_xgb)\n",
    "model_xgb, metrics_xgb = run_experiment(final_model_xgb, \"XGBoost_Optuna\", best_params_xgb, X_train_raw, y_train_raw, X_test_raw, y_test_raw)\n",
    "if model_xgb is not None:\n",
    "    results[\"XGBoost\"] = metrics_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================\n",
      "          –°–í–û–î–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í\n",
      "=========================================\n",
      "              mae       mse     rmse      r2    mape\n",
      "LightGBM   8.8641  342.9353  18.5185  0.3207  0.0399\n",
      "CatBoost  10.8037  396.2144  19.9051  0.2152  0.0501\n",
      "XGBoost    8.5694  324.4260  18.0118  0.3574  0.0386\n",
      "\n",
      "–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ RMSE: XGBoost (RMSE = 18.0118)\n",
      "\n",
      "--- –í—Å–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã ---\n",
      "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ MLflow UI –ø–æ –∞–¥—Ä–µ—Å—É http://84.201.144.227:8000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=========================================\\n          –°–í–û–î–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í\\n=========================================\")\n",
    "if results:\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    print(results_df.round(4))\n",
    "    if not results_df.empty:\n",
    "        best_model_name = results_df['rmse'].idxmin()\n",
    "        best_rmse = results_df.loc[best_model_name, 'rmse']\n",
    "        print(f\"\\n–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ RMSE: {best_model_name} (RMSE = {best_rmse:.4f})\")\n",
    "else:\n",
    "    print(\"–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.\")\n",
    "print(\"\\n--- –í—Å–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã ---\")\n",
    "print(\"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ MLflow UI –ø–æ –∞–¥—Ä–µ—Å—É http://84.201.144.227:8000\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
